{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# KNN to image classify CIFAR-10",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport os\n\nX_tr = []\nY_tr = []\ndir_train = './Data/train/'\nfor subdir in os.listdir(dir_train):\n    for file in os.listdir(dir_train + subdir):\n        img = plt.imread(dir_train + subdir + '/' + file)\n        label = subdir\n        X_tr.append(img)\n        Y_tr.append(label)\n        \nX_train = np.array(X_tr)\ny_train = np.array(Y_tr)\n\nprint(f'Shape of training data: {X_train.shape}')\nprint(f'Shape of training Label: {y_train.shape}')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X_te = []\nY_te = []\ndir_test = './Data/test/'\nfor subdir in os.listdir(dir_test):\n    for file in os.listdir(dir_test + subdir):\n        img = plt.imread(dir_test + subdir + '/' + file)\n        label = subdir\n        X_te.append(img)\n        Y_te.append(label)\n        \nX_test = np.array(X_te)\ny_test = np.array(Y_te)\n\nprint(f'Shape of testing data: {X_test.shape}')\nprint(f'Shape of testing Label: {y_test.shape}')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class KNN(object):\n    def __init__(self):\n        pass\n    \n    def train(self, X, y):\n        self.X_train = X\n        self.y_train = y\n        \n    def predict(self, X, k=1, num_loops=0):\n        if num_loops == 0:\n            dists = self.compute_distances(X)\n        else:\n            raise ValueError(f'Invalid value {num_loops} for num_loops')\n        return self.predict_labels(dists, k=k)\n    \n    def compute_distances(self, X):\n        num_test = X.shape[0]\n        num_train = self.X_train.shape[0]\n        dists = np.zeros((num_test, num_train), dtype=np.longlong)\n        for i in range(num_test):\n            for j in range(num_train):\n                dists[i, j] = abs(X[i].sum() - self.X_train[j].sum())\n        return dists\n        \n    def predict_labels(self, dists, k=1):\n        num_test = dists.shape[0]\n        y_pred = [''] * num_test\n        for i in range(num_test):\n            closest_y = []\n            sorted_dist = np.argsort(dists[i])\n            closest_y = list(self.y_train[sorted_dist[0:k]])\n            y_pred[i]= max(closest_y, key=closest_y.count)\n        return y_pred",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "classifier = KNN()\nclassifier.train(X_train, y_train)\ndists = classifier.compute_distances(X_test)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "K_values = []\nAccuracy_values = []\nfor j in range(1, 21):\n    y_test_pred = classifier.predict_labels(dists, k=j)\n    num_correct = 0\n    for i in range(len(y_test_pred)):\n        if y_test[i] == y_test_pred[i]:\n            num_correct += 1\n    accuracy = float((num_correct) * 2 * 100) / len(y_test_pred)\n    K_values.append(j)\n    Accuracy_values.append(accuracy)\n\nprint(len(K_values))\n    \nfor i in range(20):\n    print(f'Accuracy for K value of {K_values[i]} is: {Accuracy_values[i]}')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "X = np.array(K_values)\nY = np.array(Accuracy_values)\nplt.plot(X, Y, 'go', linewidth=2, markersize=5)\nplt.ylim([20, 30])\nplt.xlim([0, 21])\nplt.xlabel('K_values')\nplt.ylabel('Accuracy(%)')\nplt.grid()\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "#Result Analysis\n\nThe abbreviation KNN stands for “K-Nearest Neighbour”. It is a supervised machine learning algorithm. The algorithm can be used to solve both classification and regression problem statements. It was developed by Evelyn Fix and Joseph Hodges in 1951. The KNN algorithm can compete with the most accurate models because it makes highly accurate predictions. Therefore, you can use the KNN algorithm for applications that require high accuracy but that do not require a human-readable model. The quality of the predictions depends on the distance measure. In this implementation, it was an attept to undertake to classify the cifar 10 images dataset. In this implementation, the accuracy is not satisfactory. So we can say that KNN (K-Nearest Neighbour) is not the perfect algorithm for image classification.",
      "metadata": {}
    }
  ]
}